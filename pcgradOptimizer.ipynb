{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PcGrad Implementation using Python\n",
    "Pc-Grad is an optimized gradient descent algorithm which is mainly used for multitask-training."
   ],
   "id": "5b897535d50ec009"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T18:54:44.270748Z",
     "start_time": "2025-08-22T18:54:40.620829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from torch.optim.adamw import adamw"
   ],
   "id": "83f190e11654d957",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PCGrad():\n",
    "    def __init__(self, optimizer, reduction='mean'):\n",
    "        self.optimizer = optimizer\n",
    "        return\n",
    "\n",
    "    def zero_grad(self):\n",
    "        return self.optimizer.zero_grad()(set_to_none=True)\n",
    "\n",
    "    def pack_gradient(self, objectives):\n",
    "        grads, shapes, has_grads = [], [], []\n",
    "        for objective in objectives:\n",
    "            self.optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use a seed for replication and assign random values for input and expected results for testing. Further specifiy a fixed\n",
    "tensor assuming it's a prediction."
   ],
   "id": "c08ea8b072385c9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T19:04:20.696061Z",
     "start_time": "2025-08-22T19:04:20.692231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(4)\n",
    "input, expectations = torch.randn(2, 3), torch.randn(2, 4)\n",
    "predictions = torch.tensor([[-1.6053,  0.2325,  2.2399],\n",
    "                           [ 0.8473,  1.2006, -0.4016]])\n",
    "print(x,y)\n"
   ],
   "id": "2ea849e23ec7d919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6053,  0.2325,  2.2399],\n",
      "        [ 0.8473,  1.2006, -0.4016]]) tensor([[-1.4260,  0.9039,  0.8557,  0.6889],\n",
      "        [ 0.8850,  1.7706, -0.0809,  0.0513]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Compute the losses of the current predictions from the model. First use the derivation of the MSE functions\n",
    "and then apply the loss functions on the input and predictions done by the model, this is\n",
    "our starting point for PCGrad."
   ],
   "id": "6883f63be22f42ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T19:04:22.069148Z",
     "start_time": "2025-08-22T19:04:22.065303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss1_fn, loss2_fn = nn.L1Loss(), nn.MSELoss()\n",
    "print(loss1_fn(input, predictions), loss2_fn(input, predictions))"
   ],
   "id": "369dbe1169de95df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8007e-05) tensor(1.0211e-09)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a random tensor which is considered as our parameters. Then initialize an optimizer.",
   "id": "40e1598280c1b468"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parameter = torch.randn(2, 3)\n",
    "optimizer = torch.optim.Adam(parameter)"
   ],
   "id": "5c50b94f2b1ccf02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we compute the projected conflicted gradient or the gradients for the give loss objectives.",
   "id": "e7029744bcfa6394"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def pc_backward(objectives):\n",
    "    grads, shapes, has_grads = pc_package_grad(objectives)"
   ],
   "id": "927d9263c4294367"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def pc_package_grad(objectives):\n",
    "    grads, shapes, has_grads = [], [], []\n",
    "    for objective in objectives:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        objective.backward(retain_grad=True)\n",
    "        grad, shape, has_grad = pc_retrieve_grad()"
   ],
   "id": "1f8f4e36a4413893"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The function will get the gradient of the parameters form the given model/network with specific objective.\n",
    "It will differentiate between gradients that actually present in the given parameter tensor or not.\n"
   ],
   "id": "7052c4eccba7ddba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def pc_retrieve_grad(self):\n",
    "    grad, shape, has_grad = [], [], []\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is None:\n",
    "                shape.append(param.shape)\n",
    "                grad.append(torch.zeros_like(param).to(param.device))\n",
    "                has_grad.append(torch.zeros_like(param).to(param.device))\n",
    "                continue\n",
    "            shape.append(param.grad.shape)\n",
    "            grad.append(param.grad.clone())\n",
    "            has_grad.append(torch.ones_like(param).to(param.device))\n",
    "    return grad, shape, has_grad\n"
   ],
   "id": "a31906a8bb3545a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7f902658d7983dc0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
